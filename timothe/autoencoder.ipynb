{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd \n",
    "import random \n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from NN.model_for_mnist import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os.path import join\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "from noise import *\n",
    "\n",
    "dataset_name = 'datasets/08_mnist_sum_noise_level'\n",
    "X_labeled = np.load(join(dataset_name, \"X_labeled.npy\"))\n",
    "y_labeled = np.load(join(dataset_name, \"y_labeled.npy\"))\n",
    "X_unlabeled = np.load(join(dataset_name, \"X_unlabeled.npy\"))\n",
    "X_val = np.load(join(dataset_name, \"X_val.npy\"))\n",
    "\n",
    "batch_size=256\n",
    "\n",
    "def get_data_loader(X, batch_size):\n",
    "    tensor_x = torch.Tensor(X) # transform to torch tensor\n",
    "    my_dataset = TensorDataset(tensor_x) # create your datset\n",
    "    return DataLoader(my_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#train_loader = get_data_loader(X_unlabeled, batch_size)\n",
    "#val_loader = get_data_loader(X_val, batch_size)\n",
    "\n",
    "train_dataset = get_data_loader(X_unlabeled, batch_size)\n",
    "test_dataset = get_data_loader(X_val, batch_size)\n",
    "\n",
    "#train_dataset = torchvision.datasets.MNIST(dataset_name, train=True, download=False)\n",
    "#test_dataset  = torchvision.datasets.MNIST(dataset_name, train=False, download=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset.transform = train_transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "m=len(train_dataset)\n",
    "\n",
    "train_data, val_data = random_split(train_dataset, [int(m-m*0.2), int(m*0.2)])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "valid_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(3 * 3 * 32, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(encoded_space_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 3 * 3 * 32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, \n",
    "        unflattened_size=(32, 3, 3))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, \n",
    "            stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, \n",
    "            padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, \n",
    "            padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr= 0.001\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "### Initialize the two networks\n",
    "d = 12\n",
    "\n",
    "#model = Autoencoder(encoded_space_dim=encoded_space_dim)\n",
    "encoder = Encoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder(encoded_space_dim=d,fc2_input_dim=128)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_noise(inputs,noise_factor=0.3):\n",
    "     noisy = inputs+torch.randn_like(inputs) * noise_factor\n",
    "     noisy = torch.clip(noisy,0.,1.)\n",
    "     return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Training function\n",
    "def train_epoch_den(encoder, decoder, device, dataloader, loss_fn, optimizer,noise_factor=0.3):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for image_batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        # Move tensor to the proper device\n",
    "        image_noisy = add_noise(image_batch,noise_factor)\n",
    "        image_batch = image_batch.to(device)\n",
    "        image_noisy = image_noisy.to(device)    \n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_noisy)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Evaluate loss\n",
    "        loss = loss_fn(decoded_data, image_batch)\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "    return np.mean(train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Testing function\n",
    "def test_epoch_den(encoder, decoder, device, dataloader, loss_fn,noise_factor=0.3):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        for image_batch, _ in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            image_noisy = add_noise(image_batch,noise_factor)\n",
    "            image_noisy = image_noisy.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_noisy)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch.cpu())\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_fn(conc_out, conc_label)\n",
    "    return val_loss.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_ae_outputs_den(encoder,decoder,n=10,noise_factor=0.3):\n",
    "    plt.figure(figsize=(16,4.5))\n",
    "    targets = test_dataset\n",
    "    t_idx = {i:np.where(targets==i) for i in range(n)}    \n",
    "    for i in range(n):\n",
    "\n",
    "      ax = plt.subplot(3,n,i+1)\n",
    "      img = test_dataset\n",
    "      X_label_noise = add_noise(torch.Tensor(img) ,noise_factor)\n",
    "      X_label_noise = X_label_noise.to(device)\n",
    "\n",
    "      encoder.eval()\n",
    "      decoder.eval()\n",
    "\n",
    "      with torch.no_grad():\n",
    "         X_label_res  = decoder(encoder(X_label_noise))\n",
    "\n",
    "      plt.imshow(img[i, 0], cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(3, n, i + 1 + n)\n",
    "      plt.imshow(X_label_noise[i, 0], cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Corrupted images')\n",
    "\n",
    "      ax = plt.subplot(3, n, i + 1 + n + n)\n",
    "      plt.imshow(X_label_res[i, 0], cmap='gist_gray')  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.7, \n",
    "                    top=0.9, \n",
    "                    wspace=0.3, \n",
    "                    hspace=0.3)     \n",
    "    plt.show()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Training cycle\n",
    "noise_factor = 0.3\n",
    "num_epochs = 30\n",
    "history_da={'train_loss':[],'val_loss':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
    "    ### Training (use the training function)\n",
    "    train_loss=train_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=train_loader, \n",
    "        loss_fn=loss_fn, \n",
    "        optimizer=optim,noise_factor=noise_factor)\n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_epoch_den(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=valid_loader, \n",
    "        loss_fn=loss_fn,noise_factor=noise_factor)\n",
    "    # Print Validationloss\n",
    "    history_da['train_loss'].append(train_loss)\n",
    "    history_da['val_loss'].append(val_loss)\n",
    "    print('\\n EPOCH {}/{} \\t train loss {:.3f} \\t val loss {:.3f}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n",
    "    plot_ae_outputs_den(encoder,decoder,noise_factor=noise_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), \"models/encoder.pth\")\n",
    "torch.save(decoder.state_dict(), \"models/decoder.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "encoder = torch.load(\"models/encoder.pth\")\n",
    "decoder = torch.load(\"models/decoder.pth\")\n",
    "\n",
    "# Restore the model\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,fc2_input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(3 * 3 * 32, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.encoder_lin(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "encoder = Encoder(12, 128)\n",
    "encoder.load_state_dict(torch.load(\"models/encoder.pth\"))\n",
    "\n",
    "encoder\n",
    "\n",
    "decoder = Decoder(12, 128)\n",
    "decoder.load_state_dict(torch.load(\"models/decoder.pth\"))\n",
    "\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exo 8\n",
    "#decoder(encoder(X_val))\n",
    "\n",
    "dataset_name = 'datasets/08_mnist_sum_noise_level'\n",
    "X_labeled = np.load(join(dataset_name, \"X_labeled.npy\"))\n",
    "y_labeled = np.load(join(dataset_name, \"y_labeled.npy\"))\n",
    "X_unlabeled = np.load(join(dataset_name, \"X_unlabeled.npy\"))\n",
    "X_val = np.load(join(dataset_name, \"X_val.npy\"))\n",
    "\n",
    "X_lab_noise = torch.Tensor(X_labeled)\n",
    "X_label_noise = decoder(encoder(X_lab_noise))\n",
    "print(X_label_noise.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
